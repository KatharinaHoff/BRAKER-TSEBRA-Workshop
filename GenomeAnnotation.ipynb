{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed52c95-07b9-4410-9897-39c1360e3fb5",
   "metadata": {},
   "source": [
    "# Genome Annotation\n",
    "\n",
    "Materials for a BRAKER & TSEBRA Genome Annotation workshop by Katharina Hoff (katharina.hoff@uni-greifswald.de).\n",
    "\n",
    "Please find slides for an introductory talk on genome annotation (with BRAKER and TSEBRA) at [braker_response_2022.pdf](braker_response_2022.pdf)\n",
    "\n",
    "In the following, we will walk through the process of genome annotation on the example of a small proportion of the *Arabidopsis thaliana* genome.\n",
    "\n",
    "## Repeat masking\n",
    "\n",
    "Repetitive sequences are a huge problem for genome annotation. Some repeats only coincidentally look like protein-coding genes, others (such as transposases) are protein-coding genes, but we usually are not interested in any of these \"repeat genes\" when trying to find protein-coding genes in a novel genome. Thus, a genome should be repeat-masked prior gene prediction. \n",
    "\n",
    "Repeat masking is a resource and time-consuming step that is out of scope for this short session. We recommend using RepeatModeler2 (paper at https://doi.org/10.1073/pnas.1921046117 , software at https://www.repeatmasker.org/RepeatModeler/ ) to construct a species-specific repeat library and mask the genome with RepeatMasker (ideally, you will perform these computations on a node >70 threads, in a place with very fast storage i/o):\n",
    "\n",
    "```\n",
    "T=72 # you need a large number of threads and fast i/o storage\n",
    "GENOME=genome.fa\n",
    "DB=some_db_name_that_fits_to_species\n",
    "\n",
    "BuildDatabase -name ${DB} ${GENOME}\n",
    "RepeatModeler -database ${DB} -pa ${T} -LTRStruct\n",
    "RepeatMasker -pa 72 -lib ${DB}-families.fa -xsmall ${GENOME}\n",
    "```\n",
    "\n",
    "This results in a file `${GENOME}.masked`. \n",
    "\n",
    "<details>\n",
    "  <summary>Click to learn how to mask more rigorously when needed</summary>\n",
    "Depending on the kind of genome, plenty of unmasked repeats may still persist. This is general an issue to be expected in large genomes, such as vertebrate genomes, and you will notice the problem if the count of predicted proteins is extremely high. You can try to overcome \"under-masking\" with the following steps:\n",
    "\n",
    "```\n",
    "ln -s genome.masked.fa genome.fa\n",
    "splitMfasta.pl --minsize=25000000 ${GENOME}.masked\n",
    "\n",
    "# Running TRF\n",
    "ls genome.split.*.fa | parallel 'trf {} 2 7 7 80 10 50 500 -d -m -h'\n",
    "\n",
    "# Parsing TRF output\n",
    "# The script parseTrfOutput.py is from https://github.com/gatech-genemark/BRAKER2-exp\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat | parallel 'parseTrfOutput.py {} --minCopies 1 --statistics {}.STATS > {}.raw.gff 2> {}.parsedLog'\n",
    "\n",
    "# Sorting parsed output...\"\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff | parallel 'sort -k1,1 -k4,4n -k5,5n {} > {}.sorted 2> {}.sortLog'\n",
    "\n",
    "# Merging gff...\n",
    "FILES=genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff.sorted\n",
    "for f in $FILES\n",
    "do\n",
    "    bedtools merge -i $f | awk 'BEGIN{OFS=\"\\t\"} {print $1,\"trf\",\"repeat\",$2+1,$3,\".\",\".\",\".\",\".\"}' > $f.merged.gff 2> $f.bedtools_merge.log\n",
    "done\n",
    "\n",
    "# Masking FASTA chunk\n",
    "ls genome.split.*.fa | parallel 'bedtools maskfasta -fi {} -bed {}.2.7.7.80.10.50.500.dat.raw.gff.sorted.merged.gff -fo {}.combined.masked -soft &> {}.bedools_mask.log'\n",
    "\n",
    "# Concatenate split genome\n",
    "cat genome.split.*.fa.combined.masked > genome.fa.combined.masked\n",
    "```\n",
    "\n",
    "The file `genome.fa.combined.masked` will be more rigorously masked.\n",
    "</details>\n",
    "\n",
    "## RNA-Seq alignment with HiSat2\n",
    "\n",
    "Spliced alignments of RNA-Seq short reads are a valuable information source for predicting protein-coding genes with high accuracy.\n",
    "\n",
    "![Figure 3 of Lomsadze et al. (2014)](et-rnaseq.png \"Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET).\")\n",
    "Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET), image source: https://doi.org/10.1093/nar/gku557.\n",
    "\n",
    "We will map the *Arabidopsis thaliana* Illumina RNA-Seq reads from library SRR934391 in files [~/alphafold_data/response/sra/SRR934391_1.fastq.gz](~/alphafold_data/response/sra/SRR934391_1.fastq.gz) and [~/alphafold_data/response/sra/SRR934391_2.fastq.gz](~/alphafold_data/response/sra/SRR934391_2.fastq.gz). These are paired-end data, i.e. one file contains the forward reads while the other contains in the same order the reverse reads. The length of reads is in this case 100 nt.\n",
    "\n",
    "We will use HiSat2 (publication at https://doi.org/10.1038/s41587-019-0201-4 , software at https://github.com/DaehwanKimLab/hisat2) to align these reads against a chunk of the *Arabidopsis thaliana* genome contained in the file [genome.fa](genome.fa). (You can in principle use any alignment tool capable of aligning RNA-seq reads to a genome, as long as it can perform spliced alignment.)\n",
    "\n",
    "First, we need to build an index from the genome file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09c4a2-b87b-43ee-8685-53f3e927f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "if ! [ -f genome.fa ]\n",
    "then\n",
    "    ln -s /opt/BRAKER/example/genome.fa genome.fa\n",
    "fi\n",
    "\n",
    "hisat2-build genome.fa genome-idx 1> hisat2-build.log 2> hisat2-build.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf6d40-4dbe-4a25-88fb-d7d0e78da124",
   "metadata": {},
   "source": [
    "Inspect the log files [hisat2-build.log](hisat2-build.log) and [hisat2-build.err](hisat2-build.err) for possible errors.\n",
    "\n",
    "Next, we align the RNA-seq reads against the genome. Consider to **not** do this during the session. Performing this alignment took about 7 minutes with 70 threads. The precomputed output file is provided at `${HOME}/alphafold_data/response/sra/SRR934391.sam`, and we will continue to use that pre-computed file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcd5e8-f940-4dda-b1bc-6809ef2c3cbc",
   "metadata": {},
   "source": [
    "```\n",
    "%%script bash\n",
    "\n",
    "T=70 # adjust to number of threads that you booted with\n",
    "\n",
    "RNASEQDIR=${HOME}/alphafold_data/response/sra\n",
    "\n",
    "time hisat2 -p ${T} -q -x genome-idx -1 ${RNASEQDIR}/SRR934391_1.fastq.gz \\\n",
    "    -2 ${RNASEQDIR}/SRR934391_2.fastq.gz -S rnaseq.sam \\\n",
    "    1> hisat2-align.log 2> hisat2-align.err\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63231a11-d314-4d14-ac77-be7751e1249f",
   "metadata": {},
   "source": [
    "Our goal is to extract information on spliced alignments/intron positons from the alignment output file. To achieve this, we will use a tool called bam2hints that is part of the Augustus software suite (software at https://github.com/Gaius-Augustus/Augustus ). However, this tool requires a sorted bam-file. Therefore, we first convert the sam file to bam format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e1d33-a7c7-4cfe-89f6-01ffc53aecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "SAMFILE=${HOME}/alphafold_data/response/sra/SRR934391.sam\n",
    "\n",
    "samtools view -@${T} -bSh ${SAMFILE} -o rnaseq.bam\n",
    "\n",
    "# if you computed your own rnaseq.sam file, delete it to save space on harddrive\n",
    "if [ -f rnaseq.sam ]\n",
    "then\n",
    "    rm rnaseq.sam\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67019eb-65c2-49ee-97cf-29259ee96fa9",
   "metadata": {},
   "source": [
    "Then, we sort that bam file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d462ce90-278c-49b5-b0ed-3f5d09aad94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "samtools sort -@${T} -n rnaseq.bam -o rnaseq.s.bam\n",
    "rm rnaseq.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c2d3b-d003-4e4b-95f6-d40dbcb9f103",
   "metadata": {},
   "source": [
    "## Annotation of protein coding genes\n",
    "\n",
    "Structural genome annotation is ideally performed by a combination of a statistical model (e.g. Hidden Markov Model derivate) and extrinsic evidence (e.g. from transcriptomics). The statistical model parameters have to be adapted to the genomic properties of novel species. For adapting parameters, an initial set of high-quality training genes from the target species is required. This is tricky to obtain. BRAKER is a perl script that comprises several pipelines to automated the solution of this problem: fully automatically generate an initial set of training genes, train gene finders, and then predict genes with the trained parameters and extrinsic evidence.\n",
    "\n",
    "We will take an approach to structural genome annotation that takes advantage both of RNA-Seq supported gene prediction with BRAKER1 (paper at https://doi.org/10.1093/bioinformatics/btv661, software at https://github.com/Gaius-Augustus/BRAKER) and protein supported gene prediction with BRAKER2 (paper at https://doi.org/10.1093/nargab/lqaa108). This will result in a total of four gene sets that we will combine with TSEBRA (paper at https://doi.org/10.1186/s12859-021-04482-0, software at https://github.com/Gaius-Augustus/TSEBRA).\n",
    "\n",
    "### Installation of GeneMark-ES/ET/EP\n",
    "\n",
    "GeneMark-ES/ET/EP (publications at https://doi.org/10.1093/nar/gku557 , https://doi.org/10.1093/nargab/lqaa026 , https://doi.org/10.1101/gr.081612.108 ) is a dependency of BRAKER. It was not possible to compile this software into the RESPONSE image due to a license issue. Therefore, everyone has to download and install the software by themselves. Perform the following steps:\n",
    "\n",
    "   * Go to http://exon.gatech.edu/GeneMark/license_download.cgi\n",
    "   * Select GeneMark-ES/ET/EP ver 4.69_lic LINUX 64 kernel 2.6 - 3\n",
    "   * Fill in Name = \"Your name\", Institution = \"University of Greifswald\", Country = \"Germany\"\n",
    "   * Click on agree to the license agreement\n",
    "\n",
    "On the next website, click on \"here\" to download **gmes_linux_64.tar.gz**, and click on \"64_bit\" to download a file **gm_key_64.gz**.\n",
    "\n",
    "In the AppHub, upload both files into your home directory.\n",
    "\n",
    "Execute the following code (**after downloading both files**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268cccf4-433e-4539-9a29-b9f285ebb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source ${HOME}/.bashrc\n",
    "\n",
    "#if ! [ -d ${HOME}/gmes_linux_64 ]\n",
    "#then\n",
    "    cd ${HOME}\n",
    "    gunzip gmes_linux_64.tar.gz\n",
    "    tar -xf gmes_linux_64.tar\n",
    "    export PATH=${PATH}:${HOME}/gmes_linux_64\n",
    "    echo \"export PATH=${PATH}\" >> ${HOME}/.bashrc\n",
    "    cd gmes_linux_64\n",
    "    change_path_in_perl_scripts.pl \"/opt/conda/bin/perl\" &> /dev/null\n",
    "    cd ${HOME}\n",
    "    gunzip gm_key_64.gz\n",
    "    mv gm_key_64 ${HOME}/.gm_key\n",
    "    cd ${HOME}\n",
    "    git clone https://github.com/gatech-genemark/ProtHint.git &> /dev/null\n",
    "    cp -r ${HOME}/gmes_linux_64/* ProtHint/dependencies/GeneMarkES\n",
    "    export PATH=${PATH}:${HOME}/ProtHint/bin\n",
    "    echo \"export PATH=${PATH}\" >> ${HOME}/.bashrc\n",
    "#fi\n",
    "which gmes_petap.pl\n",
    "which prothint.py # representative for the other scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300410d-0522-4f4a-9400-88d63eab6e58",
   "metadata": {},
   "source": [
    "### BRAKER1\n",
    "\n",
    "BRAKER1 uses spliced alignment information from RNA-Seq for training GeneMark-ET, for selecting a training gene set for AUGUSTUS, and for predicting genes with AUGUSTUS. For this, the bam-file with RNA-Seq information needs to be converted to \"hints\". BRAKER can perform this step automatically, but it can take a long time. Therefore, we do it separately in this session, if you want to skip this step, the output file is provided at [rnaseq.hints](rnaseq.hints):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84751e1b-178a-470b-bada-c6409b14cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "bam2hints --intronsonly --in=rnaseq.s.bam --out=rnaseq.hints # takes 3-4 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc803820-947b-4e94-8f76-6e828b6e9fa3",
   "metadata": {},
   "source": [
    "BRAKER will execute fully automated training of the gene finders GeneMark-ET and AUGUSTUS. For AUGUSTUS, a configuration directory where you have writing permissions is required. Therefore, we will in the next cell create the required data structure (this has to be done only once, even if you run BRAKER many more times, later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73700d-dacc-45a6-a4ba-582286f9c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "if ! [ -d config ]\n",
    "then\n",
    "    cp -r /usr/share/augustus/config .\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0adb72-a771-4ed5-9dfa-3ed23d70bbb0",
   "metadata": {},
   "source": [
    "Next, we will run BRAKER to predict genes in the genomic sequence with RNA-Seq evidence. Training AUGUSTUS for a novel species usually comprises a step called `etraining` that adapts species-specific parameters of the statistical model of AUGUSTUS, and a step called `optimize_augustus.pl` that optimizes meta-parameters of that model. `optimize_augustus.pl` is very time-consuming. For this session, will disable this step with `--skipOptimize`. If you ever want to annotate a real new genome, make sure to delete `--skipOptimize` from your BRAKER calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c34fe6-3fb7-443f-a026-2a8bf77d304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "source ${HOME}/.bashrc # load GeneMark location\n",
    "\n",
    "export AUGUSTUS_CONFIG_PATH=\"${PWD}/config\"\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER1 ]\n",
    "then\n",
    "    rm -rf BRAKER1\n",
    "fi\n",
    "\n",
    "braker.pl --workingdir=BRAKER1 --genome=genome.fa --hints=rnaseq.hints --softmasking \\\n",
    "    --AUGUSTUS_BIN_PATH=/usr/bin/ --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\n",
    "    --cores ${T} --gm_max_intergenic 10000 \\\n",
    "    --skipOptimize #  remember to remove this option if you are running a real job\n",
    "    # this call takes a few minutes even with --skipOptimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6a614-a5ca-445c-87d9-6c06614f1c34",
   "metadata": {},
   "source": [
    "The most important output files that we will later use for running TSEBRA are \n",
    "\n",
    "   * [BRAKER1/augustus.hints.gtf](BRAKER1/augustus.hints.gtf)\n",
    "   * [BRAKER1/GeneMark-ET/genemark.gtf](BRAKER1/GeneMark-ET/genemark.gtf)\n",
    "   * [BRAKER1/hintsfile.gff](BRAKER1/hintsfile.gff)\n",
    "   \n",
    "The file [BRAKER1/what-to-cite.txt](BRAKER1/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER1.\n",
    "   \n",
    "### BRAKER2\n",
    "\n",
    "BRAKER2 uses spliced alignment information from huge database of proteins against the target genome. Note: a set of proteins from one or a few related species are not sufficient for running BRAKER2. Such proteins can be appended to a larger database. However, BRAKER2 is not an ideal tool for recovering a complete set of proteins from a related species.\n",
    "\n",
    "The following call of BRAKER takes ~8 minutes on 8 threads, even when optimizing AUGUSTUS parameters is disabled. Consider **not** executing this during the live session, precomputed results are made available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1982c6f-b149-4e66-b7ce-d4bd6c390fc6",
   "metadata": {},
   "source": [
    "```\n",
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "ORTHODB=${HOME}/alphafold_data/response/prothint_db/odb10_plants.fasta # adjust to suitable clade\n",
    "\n",
    "source ${HOME}/.bashrc # load GeneMark location\n",
    "\n",
    "export AUGUSTUS_CONFIG_PATH=${PWD}/config\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER2 ]\n",
    "then\n",
    "    rm -rf BRAKER2\n",
    "fi\n",
    "\n",
    "time braker.pl --workingdir=BRAKER2 --genome=genome.fa \\\n",
    "    --prot_seq=${ORTHODB} --softmasking \\\n",
    "    --AUGUSTUS_BIN_PATH=/usr/bin/ \\\n",
    "    --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\n",
    "    --cores ${T} --gm_max_intergenic 10000 \\\n",
    "    --skipOptimize \\ # remember to remove this option if you are running a real job\n",
    "    2> braker_prothint.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3d341-e69d-4ed5-a1ef-5af40a066f74",
   "metadata": {},
   "source": [
    "The most important output files that we will later use for running TSEBRA are \n",
    "\n",
    "   * [BRAKER2/augustus.hints.gtf](BRAKER2/augustus.hints.gtf)\n",
    "   * [BRAKER2/GeneMark-EP/genemark.gtf](BRAKER2/GeneMark-EP/genemark.gtf)\n",
    "   * [BRAKER2/hintsfile.gff](BRAKER2/hintsfile.gff)\n",
    "   \n",
    "The file [BRAKER2/what-to-cite.txt](BRAKER2/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER2.\n",
    "\n",
    "### TSEBRA\n",
    "\n",
    "TSEBRA is a tool for selecting a highly accurate gene set from several input sets according to supporting extrinsic evidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8600d47-a94f-4797-b30f-f1fcad3f0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "tsebra.py -g BRAKER1/augustus.hints.gtf,BRAKER1/GeneMark-ET/genemark.gtf,BRAKER2/augustus.hints.gtf,BRAKER2/GeneMark-EP/genemark.gtf \\\n",
    "    -e BRAKER1/hintsfile.gff,BRAKER2/hintsfile.gff -o tsebra.gtf 2> tsebra.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513be99-73a5-4d19-9790-0b6ee16c45e9",
   "metadata": {},
   "source": [
    "Check the file [tsebra.log](tsebra.log) for possible errors. The final gene set is in file [tsebra.gtf](tsebra.gtf).\n",
    "\n",
    "## BUSCO assessment\n",
    "\n",
    "BUSCO (paper at https://doi.org/10.1002/cpz1.323, software at https://gitlab.com/ezlab/busco) can provide information in sensitivity with respect to a clade-specific core gene set. We will in the following extract the amino acid sequences of predicted genes, and obtain BUSCO scores for all gene sets that went into TSEBRA, and for the final gene set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8138e23-2e8e-4a2e-96a6-5c2c2a6ff827",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# getAnnoFastaFromJoingenes.py does not have executability permission in RESPONSE\n",
    "if ! [ -f getAnnoFastaFromJoingenes.py ]\n",
    "then\n",
    "    ln -s /usr/share/augustus/scripts/getAnnoFastaFromJoingenes.py getAnnoFastaFromJoingenes.py\n",
    "fi\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER1/augustus.hints.gtf -o b1-augustus\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER1/GeneMark-ET/genemark.gtf -o genemark-et\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER2/augustus.hints.gtf -o b2-augustus\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER2/GeneMark-EP/genemark.gtf -o genemark-ep\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f tsebra.gtf -o tsebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce54627-f518-4c2a-8471-7b0be3d7f31c",
   "metadata": {},
   "source": [
    "This generated the following files with protein sequences:\n",
    "\n",
    "   * [b1-augustus.aa](b1-augustus.aa)\n",
    "   * [genemark-et.aa](genemark-et.aa)\n",
    "   * [b2-augustus.aa](b2-augustus.aa)\n",
    "   * [genemark-ep.aa](genemark-ep.aa)\n",
    "   * [tsebra.aa](tsebra.aa)\n",
    "   \n",
    "Let's have a quick look at the number of transcript produced in each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c78b0a-354a-4af9-8a9f-6cc91b1a351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "grep -c \">\" *.aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c611ea56-31b1-4b63-8a1c-96c71bf4b5e7",
   "metadata": {},
   "source": [
    "Next, we run a BUSCO assessment on all gene sets (see [../Session1/Session1-Assembly.ipynb](../Session1/Session1-Assembly.ipynb) about lineages, this takes ~4 minutes with 8 threads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17967a94-04d5-44e8-93b2-cec688e7488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source ../Session1/conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "GENESETS=(b1-augustus genemark-et b2-augustus genemark-ep tsebra)\n",
    "\n",
    "for s in ${GENESETS[@]}; do\n",
    "    echo \"Processing ${s}...\"\n",
    "    if [ -d busco_${s} ]\n",
    "    then\n",
    "        rm -r busco_${s}\n",
    "    fi\n",
    "    busco -m proteins -i b1-augustus.aa -o busco_${s} \\\n",
    "        -l brassicales_odb10 -c ${T} &> busco_${s}.log\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0917f0eb-4b23-4434-a604-137dcbada7a4",
   "metadata": {},
   "source": [
    "Next, we visualize the BUSCO results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308e93f-bd1c-477a-8252-584ae175e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source ../Session1/conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "if ! [ -d BUSCO_summaries ]\n",
    "then\n",
    "    mkdir BUSCO_summaries\n",
    "fi\n",
    "\n",
    "cp busco_*/short_summary*.txt BUSCO_summaries\n",
    "\n",
    "generate_plot.py -wd BUSCO_summaries &> generate_plot.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a551a-5464-4450-9fee-f910798fd844",
   "metadata": {},
   "source": [
    "Check the file [generate_plot.log](generate_plot.log) for possible errors. This results in the following figure (stored at [BUSCO_summaries/busco_figure.png](BUSCO_summaries/busco_figure.png)):\n",
    "\n",
    "<img src=\"BUSCO_summaries/busco_figure.png\" alt=\"BUSCO results\" width=\"1000\"/>\n",
    "\n",
    "The data that we used in this session was selected purely on the criterion of feasible runtime. In a real scenario, with a complete genome, the BUSCO plot should look more like this (sensitivity should increase in the final TSEBRA set):\n",
    "\n",
    "<img src=\"busco_ideally.png\" alt=\"BUSCO results (ideally)\" width=\"1000\"/>\n",
    "\n",
    "## Data visualization in the UCSC Genome Browser\n",
    "\n",
    "Visualization of gene structures in context with extrinsic evidence is essential for coming to a decision on whether a gene set \"makes sense\" or \"does not make sense\". Typical problems that you may observe in a genome browser include \"split genes\" (where evidence implies two genes should in fact be a single gene) or \"joined genes\" (where evidence implies one gene should be split into two genes).\n",
    "\n",
    "The UCSC Genome Browser (publication at https://doi.org/10.1101/gr.229102) is one of the most popular genome browsers. It has the advantage that you do not have to install a browser instance on your own webserver. Instead, you only need to provide a certain data structure with your target data on a webserver. The UCSC Genome Browser servers can display your data from there. The data structures are called \"track data hubs\" or \"assembly hubs\" (paper at https://doi.org/10.1093/bioinformatics/btt637). \n",
    "\n",
    "MakeHub (paper at https://doi.org/10.1016/j.gpb.2019.05.003 , software at https://github.com/Gaius-Augustus/MakeHub ) is a python script that fully automates the generation of such track data hubs for novel genomes. In the following, we will generate a simple track data hub for the genome sequence that we annotated with BRAKER and TSEBRA (before starting this job, check whether you have around 10G of RAM available, top right corner of your web browser window):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e3029-7321-4efe-a66f-dfaef841b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "# merge hints\n",
    "cat BRAKER1/hintsfile.gff BRAKER2/hintsfile.gff > all_hints.gff\n",
    "\n",
    "make_hub.py -e katharina.hoff@uni-greifswald.de \\\n",
    "    --genome genome.fa --long_label \"A chunk from the Arabidopsis thaliana genome\" \\\n",
    "    --short_label at_chunk  --bam rnaseq.s.bam --cores ${T} \\\n",
    "    --display_bam_as_bam --latin_name \"Arabidopsis thaliana\" \\\n",
    "    --assembly_version \"artifically split custom assembly\" \\\n",
    "    --hints all_hints.gff --gene_track tsebra.gtf TSEBRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc653250-d5b7-4714-a346-e22563d67bc9",
   "metadata": {},
   "source": [
    "You can't perform the suggested `scp` command from the apphub, unless you have privileges on a University of Greifswald webserver. We have therefore copied a prepared hub in advance. The `hub.txt` is available at https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt . Remember that link.\n",
    "\n",
    "In order to visualize your data, go to https://genome.ucsc.edu/ . Click on `My Data` -> `Track Hubs` -> choose the European mirror -> click on `Connected Hubs` and enter the link https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt into the text window -> click on `Add Hub`. Congratulations, your Hub is now connected. You should be able to browse something like this: \n",
    "\n",
    "<img src=\"at_chunk.png\" alt=\"UCSC Genome Browser example\" width=\"1000\"/>\n",
    "\n",
    "### How to know which sequences to browse\n",
    "\n",
    "The long sequences are usually the most interesting to look at. The following command gives you the names of sequences in the order of descending length, you can copy-paste the sequence names into the search window in the UCSC Genome Browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd61f2-9007-45bd-83bf-5af23fee0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "N=5 # how many longest sequences would you like to know about\n",
    "\n",
    "summarizeACGTcontent.pl genome.fa | grep bases | head -${N} | sort -n \\\n",
    "   | perl -ne 'm/(\\d+)\\s+bases\\.\\s+(\\S+)/; print \"$2\\t$1\\n\";'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7681d88-0284-4819-bf10-955279525239",
   "metadata": {},
   "source": [
    "### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
