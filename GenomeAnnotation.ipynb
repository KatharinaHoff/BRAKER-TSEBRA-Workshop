{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ed52c95-07b9-4410-9897-39c1360e3fb5",
   "metadata": {},
   "source": [
    "# Genome Annotation\n",
    "\n",
    "Materials for a BRAKER & TSEBRA Genome Annotation workshop by Katharina Hoff (katharina.hoff@uni-greifswald.de).\n",
    "\n",
    "Please find slides for an introductory talk on genome annotation (with BRAKER and TSEBRA) at [braker_erga_2022.pdf](braker_erga_2022.pdf)\n",
    "\n",
    "In the following, we will walk through the process of genome annotation on the example of a small proportion of the *Arabidopsis thaliana* genome.\n",
    "\n",
    "## Repeat masking\n",
    "\n",
    "Repetitive sequences are a huge problem for genome annotation. Some repeats only coincidentally look like protein-coding genes, others (such as transposases) are protein-coding genes, but we usually are not interested in any of these \"repeat genes\" when trying to find protein-coding genes in a novel genome. Thus, a genome should be repeat-masked prior gene prediction. \n",
    "\n",
    "Repeat masking is a resource and time-consuming step that is out of scope for this workshop. We recommend using RepeatModeler2 (paper at https://doi.org/10.1073/pnas.1921046117 , software at https://www.repeatmasker.org/RepeatModeler/ ) to construct a species-specific repeat library and mask the genome with RepeatMasker (ideally, you will perform these computations on a node with >70 threads, in a place with very fast storage i/o, possibly using RAM instead of actual hard drive as a temporary file storage place):\n",
    "\n",
    "```\n",
    "T=72 # you need a large number of threads and fast i/o storage\n",
    "GENOME=genome.fa\n",
    "DB=some_db_name_that_fits_to_species\n",
    "\n",
    "BuildDatabase -name ${DB} ${GENOME}\n",
    "RepeatModeler -database ${DB} -pa ${T} -LTRStruct\n",
    "RepeatMasker -pa 72 -lib ${DB}-families.fa -xsmall ${GENOME}\n",
    "```\n",
    "\n",
    "This results in a file `${GENOME}.masked`. \n",
    "\n",
    "<details>\n",
    "  <summary>Click to learn how to mask more rigorously when needed</summary>\n",
    "Depending on the kind of genome, plenty of unmasked repeats may still persist. This is generally an issue to be expected in large genomes, such as vertebrate genomes, and you will notice the problem if the count of predicted proteins is extremely high. You can try to overcome \"under-masking\" with the following steps (we are suggesting to use GNU parallel to speed up the process):\n",
    "\n",
    "```\n",
    "ln -s genome.masked.fa genome.fa\n",
    "splitMfasta.pl --minsize=25000000 ${GENOME}.masked\n",
    "\n",
    "# Running TRF\n",
    "ls genome.split.*.fa | parallel 'trf {} 2 7 7 80 10 50 500 -d -m -h'\n",
    "\n",
    "# Parsing TRF output\n",
    "# The script parseTrfOutput.py is from https://github.com/gatech-genemark/BRAKER2-exp\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat | parallel 'parseTrfOutput.py {} --minCopies 1 --statistics {}.STATS > {}.raw.gff 2> {}.parsedLog'\n",
    "\n",
    "# Sorting parsed output...\"\n",
    "ls genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff | parallel 'sort -k1,1 -k4,4n -k5,5n {} > {}.sorted 2> {}.sortLog'\n",
    "\n",
    "# Merging gff...\n",
    "FILES=genome.split.*.fa.2.7.7.80.10.50.500.dat.raw.gff.sorted\n",
    "for f in $FILES\n",
    "do\n",
    "    bedtools merge -i $f | awk 'BEGIN{OFS=\"\\t\"} {print $1,\"trf\",\"repeat\",$2+1,$3,\".\",\".\",\".\",\".\"}' > $f.merged.gff 2> $f.bedtools_merge.log\n",
    "done\n",
    "\n",
    "# Masking FASTA chunk\n",
    "ls genome.split.*.fa | parallel 'bedtools maskfasta -fi {} -bed {}.2.7.7.80.10.50.500.dat.raw.gff.sorted.merged.gff -fo {}.combined.masked -soft &> {}.bedools_mask.log'\n",
    "\n",
    "# Concatenate split genome\n",
    "cat genome.split.*.fa.combined.masked > genome.fa.combined.masked\n",
    "```\n",
    "\n",
    "The file `genome.fa.combined.masked` will be more rigorously masked.\n",
    "</details>\n",
    "\n",
    "## RNA-Seq alignment with HiSat2\n",
    "\n",
    "Spliced alignments of RNA-Seq short reads are a valuable information source for predicting protein-coding genes with high accuracy.\n",
    "\n",
    "![Figure 3 of Lomsadze et al. (2014)](et-rnaseq.png \"Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET).\")\n",
    "Figure 3 of Lomsadze et al. (2014) illustrates the use of RNA-Seq spliced alignments for predicting genes (with GeneMark-ET), image source: https://doi.org/10.1093/nar/gku557.\n",
    "\n",
    "We will map the *Arabidopsis thaliana* Illumina RNA-Seq reads from library SRR934391 in files [~/alphafold_data/response/sra/SRR934391_1.fastq.gz](~/alphafold_data/response/sra/SRR934391_1.fastq.gz) and [~/alphafold_data/response/sra/SRR934391_2.fastq.gz](~/alphafold_data/response/sra/SRR934391_2.fastq.gz). These are paired-end data, i.e. one file contains the forward reads while the other contains in the same order the reverse reads. The length of reads is in this case 100 nt.\n",
    "\n",
    "We will use HiSat2 (publication at https://doi.org/10.1038/s41587-019-0201-4 , software at https://github.com/DaehwanKimLab/hisat2) to align these reads against a chunk of the *Arabidopsis thaliana* genome contained in the file [genome.fa](genome.fa). (You can in principle use any alignment tool capable of aligning RNA-seq reads to a genome, as long as it can perform spliced alignment.)\n",
    "\n",
    "First, we need to build an index from the genome file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d09c4a2-b87b-43ee-8685-53f3e927f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# a toy data set to be used in this session is stored within the docker container\n",
    "# if not done so, yet, we copy that file into our current working directory\n",
    "if ! [ -f genome.fa ]\n",
    "then\n",
    "    ln -s /opt/BRAKER/example/genome.fa genome.fa\n",
    "fi\n",
    "\n",
    "# building the hisat2 index\n",
    "hisat2-build genome.fa genome-idx 1> hisat2-build.log 2> hisat2-build.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf6d40-4dbe-4a25-88fb-d7d0e78da124",
   "metadata": {},
   "source": [
    "Inspect the log files [hisat2-build.log](hisat2-build.log) and [hisat2-build.err](hisat2-build.err) for possible errors.\n",
    "\n",
    "Next, we align the RNA-seq reads against the genome. Consider to **not** do this during the session. Performing this alignment took about 7 minutes with 70 threads. The precomputed output file is provided at `${HOME}/alphafold_data/response/sra/SRR934391.sam`, and we will continue to use that pre-computed file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5b0d5c9-ae0e-47d5-aa06-c76ed2fd8bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t5m17.120s\n",
      "user\t15m4.275s\n",
      "sys\t11m22.905s\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with\n",
    "\n",
    "RNASEQDIR=${HOME}/alphafold_data/response/sra\n",
    "\n",
    "time hisat2 -p ${T} -q -x genome-idx -1 ${RNASEQDIR}/SRR934391_1.fastq.gz \\\n",
    "    -2 ${RNASEQDIR}/SRR934391_2.fastq.gz -S rnaseq.sam \\\n",
    "    1> hisat2-align.log 2> hisat2-align.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63231a11-d314-4d14-ac77-be7751e1249f",
   "metadata": {},
   "source": [
    "Our goal is to extract information on spliced alignments/intron positons from the alignment output file. To achieve this, we will use a tool called bam2hints that is part of the Augustus software suite (software at https://github.com/Gaius-Augustus/Augustus ). However, this tool requires a sorted bam-file. Therefore, we first use Samtools (paper at https://doi.org/10.1093/bioinformatics/btp352 , software at https://github.com/samtools ) to convert the sam file to bam format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038e1d33-a7c7-4cfe-89f6-01ffc53aecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with, takes ~2 minutes with 6 threads\n",
    "\n",
    "SAMFILE=${HOME}/alphafold_data/response/sra/SRR934391.sam\n",
    "\n",
    "samtools view -@${T} -bSh ${SAMFILE} -o rnaseq.bam\n",
    "\n",
    "# if you computed your own rnaseq.sam file, delete it to save space on harddrive\n",
    "if [ -f rnaseq.sam ]\n",
    "then\n",
    "    rm rnaseq.sam\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67019eb-65c2-49ee-97cf-29259ee96fa9",
   "metadata": {},
   "source": [
    "Then, we sort that bam file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d462ce90-278c-49b5-b0ed-3f5d09aad94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[bam_sort_core] merging from 2 files and 6 in-memory blocks...\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with, takes ~2 minutes with 6 threads\n",
    "\n",
    "samtools sort -@${T} -n rnaseq.bam -o rnaseq.s.bam\n",
    "\n",
    "# remove the unsorted bam file to save space\n",
    "rm rnaseq.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c2d3b-d003-4e4b-95f6-d40dbcb9f103",
   "metadata": {},
   "source": [
    "## Annotation of protein coding genes\n",
    "\n",
    "Structural genome annotation is ideally performed by a combination of a statistical model (e.g. Hidden Markov Model derivate) and extrinsic evidence (e.g. from transcriptomics). The statistical model parameters have to be adapted to the genomic properties of novel species. For adapting parameters, an initial set of high-quality training genes from the target species is required. This is tricky to obtain. BRAKER is a perl script that comprises several pipelines to automated the solution of this problem: fully automatically generate an initial set of training genes, train gene finders, and then predict genes with the trained parameters and extrinsic evidence.\n",
    "\n",
    "We will take an approach to structural genome annotation that takes advantage both of RNA-Seq supported gene prediction with BRAKER1 (paper at https://doi.org/10.1093/bioinformatics/btv661, all BRAKER software at https://github.com/Gaius-Augustus/BRAKER) and protein supported gene prediction with BRAKER2 (paper at https://doi.org/10.1093/nargab/lqaa108). This will result in a total of four gene sets (1 from GeneMark-ET, 1 from GeneMark-EP, two from AUGUSTUS) that we will combine with TSEBRA (paper at https://doi.org/10.1186/s12859-021-04482-0, software at https://github.com/Gaius-Augustus/TSEBRA).\n",
    "\n",
    "### Installation of GeneMark-ES/ET/EP\n",
    "\n",
    "GeneMark-ES/ET/EP (publications at https://doi.org/10.1093/nar/gku557 , https://doi.org/10.1093/nargab/lqaa026 , https://doi.org/10.1101/gr.081612.108 ) is a dependency of BRAKER. It was not possible to compile this software into the Docker container due to a license issue. Therefore, everyone has to download and install the software by themselves. Perform the following steps:\n",
    "\n",
    "   * Go to http://exon.gatech.edu/GeneMark/license_download.cgi\n",
    "   * Select GeneMark-ES/ET/EP ver 4.69_lic LINUX 64 kernel 2.6 - 3\n",
    "   * Fill in Name = \"Your name\", Institution = \"University of Greifswald\", Country = \"Germany\"\n",
    "   * Click on agree to the license agreement\n",
    "\n",
    "On the next website, click on \"here\" to download **gmes_linux_64.tar.gz**, and click on \"64_bit\" to download a file **gm_key_64.gz**.\n",
    "\n",
    "In the AppHub, upload both files into your home directory.\n",
    "\n",
    "Execute the following code (**after downloading both files and uploading them into the AppHub**) to install both GeneMark-ES/ET/EP and ProtHint, a dependency of GeneMark-EP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "268cccf4-433e-4539-9a29-b9f285ebb5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not install GeneMark. Either it was already installed (two executable files can be found below), or you need to ask for help with the installation\n",
      "/home/jovyan/gmes_linux_64/gmes_petap.pl\n",
      "/home/jovyan/ProtHint/bin/prothint.py\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# if you already have a bashrc file, load environment from there\n",
    "if [ -f ${HOME}/.bashrc ]; then\n",
    "    source ${HOME}/.bashrc\n",
    "fi\n",
    "\n",
    "if [ ! -d ${HOME}/gmes_linux_64 ]  && [ -f ${HOME}/gmes_linux_64.tar.gz ] && [ -f ${HOME}/gm_key_64.gz ]\n",
    "# if no extracted gmes_linux_64 folder exists yet and if you uploaded both files\n",
    "then\n",
    "    # go to your home directory\n",
    "    cd ${HOME}\n",
    "    # unpack the uploaded genemark software archive\n",
    "    gunzip gmes_linux_64.tar.gz\n",
    "    tar -xf gmes_linux_64.tar\n",
    "    # expand path variable to find binaries\n",
    "    export PATH=${PATH}:${HOME}/gmes_linux_64\n",
    "    # writh path expansion to bashrc file\n",
    "    echo \"export PATH=${PATH}\" >> ${HOME}/.bashrc\n",
    "    # change to genemark directory\n",
    "    cd gmes_linux_64\n",
    "    # change perl binary in all scripts according to Docker container\n",
    "    change_path_in_perl_scripts.pl \"/opt/conda/bin/perl\" &> /dev/null\n",
    "    # change to home directory\n",
    "    cd ${HOME}\n",
    "    # unpack the license key (will expire after 200 days)\n",
    "    gunzip gm_key_64.gz\n",
    "    # place key in correct location\n",
    "    mv gm_key_64 ${HOME}/.gm_key\n",
    "    # go to home directory\n",
    "    cd ${HOME}\n",
    "    # download ProtHint pipeline (dependency of BRAKER)\n",
    "    git clone https://github.com/gatech-genemark/ProtHint.git &> /dev/null\n",
    "    # copy GeneMark-ES into ProtHint directory\n",
    "    cp -r ${HOME}/gmes_linux_64/* ProtHint/dependencies/GeneMarkES\n",
    "    # expand path to find binaries\n",
    "    export PATH=${PATH}:${HOME}/ProtHint/bin\n",
    "    # write path expansion to bashrc file\n",
    "    echo \"export PATH=${PATH}\" >> ${HOME}/.bashrc\n",
    "else\n",
    "    echo \"Did not install GeneMark-ES/ET/EP.\"\n",
    "    echo \"Either it was already installed (two executable files can be found below), or you need to ask for help with the installation\"\n",
    "fi\n",
    "\n",
    "which gmes_petap.pl # representative for GeneMark-ES/ET/EP\n",
    "which prothint.py # representative for the other scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300410d-0522-4f4a-9400-88d63eab6e58",
   "metadata": {},
   "source": [
    "### BRAKER1\n",
    "\n",
    "BRAKER1 uses spliced alignment information from RNA-Seq for training GeneMark-ET, for selecting a training gene set for AUGUSTUS, and for predicting genes with AUGUSTUS. For this, the bam-file with RNA-Seq information needs to be converted to \"hints\". BRAKER can perform this step automatically, but it can take a long time. In particular if a lot of RNA-Seq libraries and a limited job runtim on a HPC system, you should perform this step prior running BRAKER for all the libraries in parallel. Therefore, we do it separately in this session. If you want to skip this step, the output file is provided at [rnaseq.hints](rnaseq.hints):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84751e1b-178a-470b-bada-c6409b14cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "bam2hints --intronsonly --in=rnaseq.s.bam --out=rnaseq.hints # takes 3-4 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc803820-947b-4e94-8f76-6e828b6e9fa3",
   "metadata": {},
   "source": [
    "BRAKER will execute fully automated training of the gene finders GeneMark-ET and AUGUSTUS. For AUGUSTUS, a configuration directory where you have writing permissions is required. Therefore, we will in the next cell create the required data structure (this has to be done only once, even if you run BRAKER many more times, later; note that this step will become obsolete when we release BRAKER3 in January 2023):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c73700d-dacc-45a6-a4ba-582286f9c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "if ! [ -d config ]\n",
    "then\n",
    "    cp -r /usr/share/augustus/config .\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0adb72-a771-4ed5-9dfa-3ed23d70bbb0",
   "metadata": {},
   "source": [
    "Next, we will run BRAKER to predict genes in the genomic sequence with the prepared RNA-Seq intron evidence. Training AUGUSTUS for a novel species usually comprises a step called `etraining` that adapts species-specific parameters of the statistical model of AUGUSTUS, and a step called `optimize_augustus.pl` that optimizes meta-parameters of that model. `optimize_augustus.pl` is very time-consuming. For this session, will disable this step with `--skipOptimize`. If you ever want to annotate a real new genome, make sure to delete `--skipOptimize` from your BRAKER calls (and expect substantially longer runtime):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c34fe6-3fb7-443f-a026-2a8bf77d304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Wed Dec 14 12:48:53 2022: Log information is stored in file /home/jovyan/BRAKER-TSEBRA-Workshop/BRAKER1/braker.log\n",
      "#*********\n",
      "# WARNING: Number of reliable training genes is low (187). Recommended are at least 600 genes\n",
      "#*********\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with, takes ~2.5 minutes on 6 threads\n",
    "\n",
    "source ${HOME}/.bashrc # load GeneMark location\n",
    "\n",
    "export AUGUSTUS_CONFIG_PATH=\"${PWD}/config\" # tell BRAKER where to find writable AUGUSTUS parameters\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER1 ]\n",
    "then\n",
    "    rm -rf BRAKER1\n",
    "fi\n",
    "\n",
    "braker.pl --workingdir=BRAKER1 --genome=genome.fa --hints=rnaseq.hints --softmasking \\\n",
    "    --AUGUSTUS_BIN_PATH=/usr/bin/ --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\n",
    "    --cores ${T} --gm_max_intergenic 10000 \\\n",
    "    --skipOptimize #  remember to remove this option if you are running a real job\n",
    "    # this call takes a few minutes even with --skipOptimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6a614-a5ca-445c-87d9-6c06614f1c34",
   "metadata": {},
   "source": [
    "Note that BRAKER by default expects scripts and binaries in a location relative to the `$AUGUSTUS_CONFIG_PATH`. We here changed the location of the `$AUGUSTUS_CONFIG_PATH` to a writable location. Therefore, we have to tell BRAKER where the scripts and binaries are (`--AUGUSTUS_BIN_PATH`, `--AUGUSTUS_CONFIG_PATH`).\n",
    "\n",
    "The most important output files that we will later use for running TSEBRA are \n",
    "\n",
    "   * [BRAKER1/augustus.hints.gtf](BRAKER1/augustus.hints.gtf)\n",
    "   * [BRAKER1/GeneMark-ET/genemark.gtf](BRAKER1/GeneMark-ET/genemark.gtf)\n",
    "   * [BRAKER1/hintsfile.gff](BRAKER1/hintsfile.gff)\n",
    "   \n",
    "The file [BRAKER1/what-to-cite.txt](BRAKER1/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER1.\n",
    "   \n",
    "### BRAKER2\n",
    "\n",
    "BRAKER2 uses spliced alignment information from a huge database of proteins against the target genome. Note: a set of proteins from one or a few related species is not sufficient for running BRAKER2 (in such a situation, consider using GALBA, instead, software at https://github.com/Gaius-Augustus/GALBA). A particular set of proteins of a closely related species can be appended to a larger database for running BRAKER2. However, BRAKER2 is not an ideal tool for recovering a complete set of proteins from a related species.\n",
    "\n",
    "The following call of BRAKER takes ~9 minutes on 6 threads, even when optimizing AUGUSTUS parameters is disabled. Consider **not** executing this during the live session, precomputed results are made available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a2f94-fd7f-4b2d-a69c-e977764ada9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with\n",
    "\n",
    "ORTHODB=${HOME}/alphafold_data/response/prothint_db/odb10_plants.fasta # adjust to suitable clade\n",
    "\n",
    "source ${HOME}/.bashrc # load GeneMark location\n",
    "\n",
    "export AUGUSTUS_CONFIG_PATH=${PWD}/config\n",
    "\n",
    "# delete output from a possible previous run if it exists\n",
    "if [ -d BRAKER2 ]\n",
    "then\n",
    "    rm -rf BRAKER2\n",
    "fi\n",
    "\n",
    "time braker.pl --workingdir=BRAKER2 --genome=genome.fa \\\n",
    "    --prot_seq=${ORTHODB} --softmasking \\\n",
    "    --AUGUSTUS_BIN_PATH=/usr/bin/ \\\n",
    "    --AUGUSTUS_SCRIPTS_PATH=/usr/share/augustus/scripts/ \\\n",
    "    --cores ${T} --gm_max_intergenic 10000 \\\n",
    "    --skipOptimize \\ # remember to remove this option if you are running a real job\n",
    "    2> braker_prothint.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3d341-e69d-4ed5-a1ef-5af40a066f74",
   "metadata": {},
   "source": [
    "The most important output files that we will later use for running TSEBRA are \n",
    "\n",
    "   * [BRAKER2/augustus.hints.gtf](BRAKER2/augustus.hints.gtf)\n",
    "   * [BRAKER2/GeneMark-EP/genemark.gtf](BRAKER2/GeneMark-EP/genemark.gtf)\n",
    "   * [BRAKER2/hintsfile.gff](BRAKER2/hintsfile.gff)\n",
    "   \n",
    "The file [BRAKER2/what-to-cite.txt](BRAKER2/what-to-cite.txt) advises you on what papers should be cited if you were going to publish a manuscript on a gene set produced with BRAKER2.\n",
    "\n",
    "### TSEBRA\n",
    "\n",
    "TSEBRA is a tool for selecting a highly accurate gene set from several input sets according to supporting extrinsic evidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8600d47-a94f-4797-b30f-f1fcad3f0416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "tsebra.py -g BRAKER1/augustus.hints.gtf,BRAKER1/GeneMark-ET/genemark.gtf,BRAKER2/augustus.hints.gtf,BRAKER2/GeneMark-EP/genemark.gtf \\\n",
    "    -e BRAKER1/hintsfile.gff,BRAKER2/hintsfile.gff -o tsebra.gtf 2> tsebra.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513be99-73a5-4d19-9790-0b6ee16c45e9",
   "metadata": {},
   "source": [
    "Check the file [tsebra.log](tsebra.log) for possible errors. The final gene set is in file [tsebra.gtf](tsebra.gtf).\n",
    "\n",
    "## BUSCO assessment\n",
    "\n",
    "BUSCO (paper at https://doi.org/10.1002/cpz1.323, software at https://gitlab.com/ezlab/busco) can provide information on sensitivity with respect to a clade-specific core gene set. We will in the following extract the amino acid sequences of predicted genes, and obtain BUSCO scores for all gene sets that went into TSEBRA, and for the final gene set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8138e23-2e8e-4a2e-96a6-5c2c2a6ff827",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# getAnnoFastaFromJoingenes.py does not have executability permission in Docker container\n",
    "# therefore make softlink for calling it with python explicitely\n",
    "if ! [ -f getAnnoFastaFromJoingenes.py ]\n",
    "then\n",
    "    ln -s /usr/share/augustus/scripts/getAnnoFastaFromJoingenes.py getAnnoFastaFromJoingenes.py\n",
    "fi\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER1/augustus.hints.gtf -o b1-augustus\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER1/GeneMark-ET/genemark.gtf -o genemark-et\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER2/augustus.hints.gtf -o b2-augustus\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f BRAKER2/GeneMark-EP/genemark.gtf -o genemark-ep\n",
    "\n",
    "python getAnnoFastaFromJoingenes.py -g genome.fa \\\n",
    "    -f tsebra.gtf -o tsebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce54627-f518-4c2a-8471-7b0be3d7f31c",
   "metadata": {},
   "source": [
    "This generated the following files with protein sequences:\n",
    "\n",
    "   * [b1-augustus.aa](b1-augustus.aa)\n",
    "   * [genemark-et.aa](genemark-et.aa)\n",
    "   * [b2-augustus.aa](b2-augustus.aa)\n",
    "   * [genemark-ep.aa](genemark-ep.aa)\n",
    "   * [tsebra.aa](tsebra.aa)\n",
    "   \n",
    "Let's have a quick look at the number of transcript products in each file ($\\neq$ number of genes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c78b0a-354a-4af9-8a9f-6cc91b1a351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b1-augustus.aa:278\n",
      "b2-augustus.aa:300\n",
      "genemark-ep.aa:279\n",
      "genemark-et.aa:266\n",
      "tsebra.aa:318\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "grep -c \">\" *.aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abb2fe7-80ea-4fe2-9084-be860613edbf",
   "metadata": {},
   "source": [
    "First, we find the closest BUSCO lineage (we are working on *Arabidopsis thaliana*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50844f72-6582-48ab-a8af-d727a3e5ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "busco --list-datasets > busco_lineages.txt 2> busco_lineages.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8b743-b0a7-4cc8-aae6-a7ca98dfb593",
   "metadata": {},
   "source": [
    "All available lineages are now in [busco_lineages.txt](busco_lineages.txt). (Check [busco_lineages.log](busco_lineages.log) for possible errors.)\n",
    "\n",
    "Check at NCBI taxonomy (https://www.ncbi.nlm.nih.gov/taxonomy) the lineage of the target *Arabidopsis*. I believe the lineage is:\n",
    "\n",
    "`cellular organisms; Eukaryota; Viridiplantae; Streptophyta; Streptophytina; Embryophyta; Tracheophyta; Euphyllophyta; Spermatophyta; Magnoliopsida; Mesangiospermae; eudicotyledons; Gunneridae; Pentapetalae; rosids; malvids; Brassicales; Brassicaceae; Camelineae`\n",
    "\n",
    "Now find a related lineage in [busco_lineages.txt](busco_lineages.txt). `brassicales_odb10` is the closest lineage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006888e7-71ea-4560-b4c1-39c84697b56d",
   "metadata": {},
   "source": [
    "Next, we run a BUSCO assessment on all gene sets (this takes ~4 minutes with 6 threads):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17967a94-04d5-44e8-93b2-cec688e7488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing b1-augustus...\n",
      "Processing genemark-et...\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "T=6 # adjust to number of threads that you booted with\n",
    "\n",
    "GENESETS=(b1-augustus genemark-et b2-augustus genemark-ep tsebra)\n",
    "\n",
    "for s in ${GENESETS[@]}; do\n",
    "    echo \"Processing ${s}...\"\n",
    "    if [ -d busco_${s} ]\n",
    "    then\n",
    "        rm -r busco_${s}\n",
    "    fi\n",
    "    busco -m proteins -i b1-augustus.aa -o busco_${s} \\\n",
    "        -l brassicales_odb10 -c ${T} &> busco_${s}.log\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0917f0eb-4b23-4434-a604-137dcbada7a4",
   "metadata": {},
   "source": [
    "Next, we visualize the BUSCO results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9308e93f-bd1c-477a-8252-584ae175e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source conda_init\n",
    "conda activate busco_env\n",
    "\n",
    "if ! [ -d BUSCO_summaries ]\n",
    "then\n",
    "    mkdir BUSCO_summaries\n",
    "fi\n",
    "\n",
    "cp busco_*/short_summary*.txt BUSCO_summaries\n",
    "\n",
    "generate_plot.py -wd BUSCO_summaries &> generate_plot.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a551a-5464-4450-9fee-f910798fd844",
   "metadata": {},
   "source": [
    "Check the file [generate_plot.log](generate_plot.log) for possible errors. This results in the following figure (stored at [BUSCO_summaries/busco_figure.png](BUSCO_summaries/busco_figure.png)):\n",
    "\n",
    "<img src=\"BUSCO_summaries/busco_figure.png\" alt=\"BUSCO results\" width=\"1000\"/>\n",
    "\n",
    "The data that we used in this session was selected purely on the criterion of feasible runtime. In a real scenario, with a complete genome, the BUSCO plot should look more like this (sensitivity should increase in the final TSEBRA set):\n",
    "\n",
    "<img src=\"busco_ideally.png\" alt=\"BUSCO results (ideally)\" width=\"1000\"/>\n",
    "\n",
    "## Data visualization in the UCSC Genome Browser\n",
    "\n",
    "Visualization of gene structures in context with extrinsic evidence is essential for coming to a decision on whether a gene set \"makes sense\" or \"does not make sense\". Typical problems that you may observe in a genome browser include \"split genes\" (where evidence implies two genes should in fact be a single gene) or \"joined genes\" (where evidence implies one gene should be split into two genes).\n",
    "\n",
    "The UCSC Genome Browser (publication at https://doi.org/10.1101/gr.229102) is one of the most popular genome browsers. It has the advantage that you do not have to install a browser instance on your own webserver. Instead, you only need to provide a certain data structure with your target data on a webserver. The UCSC Genome Browser servers can display your data from there. The data structures are called \"track data hubs\" or \"assembly hubs\" (paper at https://doi.org/10.1093/bioinformatics/btt637). \n",
    "\n",
    "MakeHub (paper at https://doi.org/10.1016/j.gpb.2019.05.003 , software at https://github.com/Gaius-Augustus/MakeHub ) is a python script that fully automates the generation of such track data hubs for novel genomes. In the following, we will generate a simple track data hub for the genome sequence that we annotated with BRAKER and TSEBRA (before starting this job, check whether you have around 10G of RAM available, top right corner of your web browser window):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092e3029-7321-4efe-a66f-dfaef841b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "T=8 # adjust to number of threads that you booted with\n",
    "\n",
    "# merge hints\n",
    "cat BRAKER1/hintsfile.gff BRAKER2/hintsfile.gff > all_hints.gff\n",
    "\n",
    "make_hub.py -e katharina.hoff@uni-greifswald.de \\\n",
    "    --genome genome.fa --long_label \"A chunk from the Arabidopsis thaliana genome\" \\\n",
    "    --short_label at_chunk  --bam rnaseq.s.bam --cores ${T} \\\n",
    "    --display_bam_as_bam --latin_name \"Arabidopsis thaliana\" \\\n",
    "    --assembly_version \"artifically split custom assembly\" \\\n",
    "    --hints all_hints.gff --gene_track tsebra.gtf TSEBRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc653250-d5b7-4714-a346-e22563d67bc9",
   "metadata": {},
   "source": [
    "You can't perform the suggested `scp` command from the apphub, unless you have privileges on a University of Greifswald webserver. We have therefore copied a prepared hub in advance. The `hub.txt` is available at https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt . Remember that link.\n",
    "\n",
    "In order to visualize your data, go to https://genome.ucsc.edu/ . Click on `My Data` -> `Track Hubs` -> choose the European mirror -> click on `Connected Hubs` and enter the link https://bioinf.uni-greifswald.de/hubs/at_chunk/hub.txt into the text window -> click on `Add Hub`. Congratulations, your Hub is now connected. You should be able to browse something like this: \n",
    "\n",
    "<img src=\"at_chunk.png\" alt=\"UCSC Genome Browser example\" width=\"1000\"/>\n",
    "\n",
    "### How to know which sequences to browse\n",
    "\n",
    "The long sequences are usually the most interesting to look at. The following command gives you the names of sequences in the order of descending length, you can copy-paste the sequence names into the search window in the UCSC Genome Browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd61f2-9007-45bd-83bf-5af23fee0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "N=5 # how many longest sequences would you like to know about\n",
    "\n",
    "summarizeACGTcontent.pl genome.fa | grep bases | head -${N} | sort -n \\\n",
    "   | perl -ne 'm/(\\d+)\\s+bases\\.\\s+(\\S+)/; print \"$2\\t$1\\n\";'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7681d88-0284-4819-bf10-955279525239",
   "metadata": {},
   "source": [
    "### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
